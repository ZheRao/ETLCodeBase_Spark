{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae60da37",
   "metadata": {},
   "source": [
    "# import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7116d34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path \n",
    "import datetime as dt \n",
    "import os, json, time, math, requests\n",
    "from intuitlib.client import AuthClient\n",
    "import subprocess, shlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01c549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row, types as T, functions as F \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a341f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orjson\n",
    "from typing import TypedDict, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a675a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'systeminfo': {'last_load_date': '2000-01-01', 'last_fx': 1.4116},\n",
       " 'companyinfo': {'us_companies': ['MFUSA', 'MFAZ', 'MSUSA', 'MPUSA'],\n",
       "  'ca_companies': ['MSL', 'NexGen', 'MFBC', 'MPL', 'MFL']},\n",
       " 'directories': {'base': 'projects/ETLPipeline/Database',\n",
       "  'credentials': {'QBO': '.inputs/dev'},\n",
       "  'bronze': {'QBO': {'PL': 'Bronze/QBO/PL', 'GL': 'Bronze/QBO/GL'}},\n",
       "  'silver': {'QBO': {'PLV0': 'Silver/QBO/PL_v0', 'GL': 'Silver/QBO/GL'}}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = \"projects/ETLPipeline/ETLCodeBase_Spark/config/info.json\"\n",
    "with open(Path.home()/config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552278c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PL': {'columns': {'TransactionDate': 'date',\n",
       "   'TransactionType': 'str',\n",
       "   'TransactionID': 'str',\n",
       "   'DocNumber': 'str',\n",
       "   'Name': 'str',\n",
       "   'NameID': 'str',\n",
       "   'Memo': 'str',\n",
       "   'SplitAcc': 'str',\n",
       "   'SplitAccID': 'str',\n",
       "   'Amount': 'float',\n",
       "   'Balance': 'float',\n",
       "   'Location': 'str',\n",
       "   'LocationID': 'str',\n",
       "   'Class': 'str',\n",
       "   'ClassID': 'str'},\n",
       "  'locations': {},\n",
       "  'columns_QBO_meta': {'tx_date': 'TransactionDate',\n",
       "   'txn_type': 'TransactionType',\n",
       "   'doc_num': 'DocNumber',\n",
       "   'name': 'Name',\n",
       "   'dept_name': 'Location',\n",
       "   'klass_name': 'Class',\n",
       "   'memo': 'Memo',\n",
       "   'split_acc': 'SplitAcc',\n",
       "   'subt_nat_amount': 'Amount',\n",
       "   'subt_nat_amount_nt': 'Amount',\n",
       "   'rbal_nat_amount': 'Balance',\n",
       "   'rbal_nat_amount_nt': 'Balance'}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_config_path = \"projects/ETLPipeline/ETLCodeBase_Spark/config/project_config.json\"\n",
    "with open(Path.home()/project_config_path, \"r\") as f:\n",
    "    project_config = json.load(f)\n",
    "project_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f11f41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = dt.date.today()\n",
    "config[\"systeminfo\"][\"last_load_date\"] = today.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c23a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88652da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e180fc2f",
   "metadata": {},
   "source": [
    "# Job Class - task creater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0105d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job:\n",
    "    def __init__(self, light_load:bool = True, lastFY:bool = False):\n",
    "        self.today = dt.date.today()\n",
    "        current_FY = self.today.year + 1 if self.today.month >= 11 else self.today.year\n",
    "        if light_load:\n",
    "            if lastFY:\n",
    "                first_year = current_FY - 1\n",
    "            else:\n",
    "                first_year = current_FY \n",
    "        else:\n",
    "            first_year = 2019\n",
    "        self.scope = list(range(first_year, current_FY+1, 1))\n",
    "    \n",
    "    def get_fx(self):\n",
    "        key  = os.getenv(\"ALPHAVANTAGE_KEY\")\n",
    "        url  = (\"https://www.alphavantage.co/query?\"\n",
    "                \"function=CURRENCY_EXCHANGE_RATE\"\n",
    "                \"&from_currency=USD&to_currency=CAD\"\n",
    "                f\"&apikey={key}\")\n",
    "        rate = float(requests.get(url, timeout=10).json()\n",
    "                    [\"Realtime Currency Exchange Rate\"][\"5. Exchange Rate\"])\n",
    "        self.fx = rate\n",
    "\n",
    "    def check_file(self, path: Path) -> None:\n",
    "        path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ba9f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2025, 2026]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self = Job(light_load=True,lastFY=True)\n",
    "self.scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8cbe696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a585148",
   "metadata": {},
   "source": [
    "## create jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4549000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 40)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_MFL = []\n",
    "jobs_others = []\n",
    "last_day = {3: 31, 6:30, 9:30, 12:31}\n",
    "for company in config[\"companyinfo\"][\"us_companies\"] + config[\"companyinfo\"][\"ca_companies\"]:\n",
    "    if company == \"MFL\":\n",
    "        jobs = jobs_MFL \n",
    "    else:\n",
    "        jobs = jobs_others\n",
    "    fy = self.scope[0]\n",
    "    jobs.append((company,\n",
    "                 dt.date(fy-1, 10, 1),\n",
    "                 dt.date(fy-1, 12, 31)))    # add last quarter from last for fiscal year consistency\n",
    "    for year in self.scope:\n",
    "        for month in [1, 4, 7, 10]:\n",
    "            if dt.date(year,month,1) > today:\n",
    "                continue\n",
    "            jobs.append((company, \n",
    "                         dt.date(year, month, 1), \n",
    "                         dt.date(year, month+2, last_day[month+2])))\n",
    "len(jobs_MFL), len(jobs_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "646b1bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MFL', datetime.date(2024, 10, 1), datetime.date(2024, 12, 31)),\n",
       " ('MFL', datetime.date(2025, 1, 1), datetime.date(2025, 3, 31)),\n",
       " ('MFL', datetime.date(2025, 4, 1), datetime.date(2025, 6, 30)),\n",
       " ('MFL', datetime.date(2025, 7, 1), datetime.date(2025, 9, 30)),\n",
       " ('MFL', datetime.date(2025, 10, 1), datetime.date(2025, 12, 31))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_MFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a18de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80a201d7",
   "metadata": {},
   "source": [
    "## append tokens for auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "660e7fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['client_secrets.json', 'tokens.json', 'copies_Linux']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = Path.home() / config[\"directories\"][\"base\"]\n",
    "token_path = BASE_DIR / config[\"directories\"][\"credentials\"][\"QBO\"]\n",
    "os.listdir(token_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efc4d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _refresh_auth_client(company: str, config:dict) -> AuthClient:\n",
    "    \"\"\" \n",
    "        create auth_client object for company called with, return auth_client for data extraction\n",
    "    \"\"\"\n",
    "    mode = \"production\"\n",
    "    BASE_DIR = Path.home() / config[\"directories\"][\"base\"]\n",
    "    token_path = BASE_DIR / config[\"directories\"][\"credentials\"][\"QBO\"]\n",
    "    with open(token_path/\"client_secrets.json\", \"r\") as f:\n",
    "        secret = json.load(f)\n",
    "    # create auth_client object\n",
    "    if company in [\"MFUSA\",\"MPUSA\",\"MFAZ\",\"MSUSA\"]:\n",
    "        auth_client = AuthClient(client_id = secret[\"USA\"][\"client_id\"],\n",
    "                        client_secret = secret[\"USA\"][\"client_secret\"],\n",
    "                        redirect_uri = \"https://developer.intuit.com/v2/OAuth2Playground/RedirectUrl\",\n",
    "                        environment = mode)\n",
    "    else:\n",
    "        auth_client = AuthClient(client_id = secret[\"CA\"][\"client_id\"],\n",
    "                                client_secret = secret[\"CA\"][\"client_secret\"],\n",
    "                                redirect_uri = \"https://developer.intuit.com/v2/OAuth2Playground/RedirectUrl\",\n",
    "                                environment = mode)\n",
    "    # assign tokens\n",
    "    with open(token_path/\"tokens.json\", \"r\") as f:\n",
    "        tokens = json.load(f)\n",
    "    auth_client.access_token = tokens[company][\"access_token\"]\n",
    "    auth_client.refresh_token = tokens[company][\"refresh_token\"]\n",
    "    auth_client.realm_id = tokens[company][\"realm_id\"]\n",
    "    # # refresh\n",
    "    # auth_client.refresh()\n",
    "    # # save refreshed tokens\n",
    "    # tokens[company][\"access_token\"] = auth_client.access_token \n",
    "    # tokens[company][\"refresh_token\"] = auth_client.refresh_token \n",
    "    # tokens[company][\"realm_id\"] = auth_client.realm_id \n",
    "    # with open(token_path/\"tokens.json\", \"w\") as f:\n",
    "    #     json.dump(tokens, f, indent=4)\n",
    "    return auth_client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c29298a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_MFL = []\n",
    "extract_others = []\n",
    "current_company = \"\"\n",
    "for (company, start, end) in jobs_MFL + jobs_others:\n",
    "    if company != current_company:\n",
    "        # refresh company credential\n",
    "        auth_client = _refresh_auth_client(company, config)\n",
    "        current_company = company\n",
    "    if company == \"MFL\":\n",
    "        extract = extract_MFL \n",
    "    else:\n",
    "        extract = extract_others\n",
    "    extract.append({\n",
    "        \"company\": company,\n",
    "        \"realm_id\": auth_client.realm_id,\n",
    "        \"token\": auth_client.access_token,\n",
    "        \"start\": start.isoformat(),\n",
    "        \"end\": end.isoformat(),\n",
    "        \"report\": \"ProfitAndLossDetail\",\n",
    "        \"out_path\": BASE_DIR / config[\"directories\"][\"bronze\"][\"QBO\"][\"PL\"]/company/(str(start.year)+\"_\"+str(start.month)+\".json\")\n",
    "    })\n",
    "len(extract_MFL) + len(extract_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "228c4521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company': 'MFL',\n",
       " 'realm_id': 123146146745069,\n",
       " 'token': 'eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwieC5vcmciOiJIMCJ9.._8X0pJLHP_d659Wi-fM_6g.pYNgSjJ6WJyM9_VwsinMA_4DbhEHEId9X7lp4GtXiveZwtwVg184l9b3krsxDqCDDc-Wzzc4R4lGF3kL4mSCgxQvwiGHhfpmTW70KAnWC_p-jVF-iKO8Mnw-PopgF5_HmIXe83qPZntZGNMdMahCVXk8AoFmfezJwJpJIZEQEa6sh5zCVaANcwwCcP2zq_ezByplJIrjpX1UJIj7fl78GW0KBuLeQrxCpbzJlvidR37CbzjpwM48rmKpgIE_p8zub7NLMFVuqWIRsFosfDvDh4devOt9aFAQ_gquIcXMBuL_IEmB-b8aZXGy_-GacAAvJ-rVHTvUna6Pq7qAXarP5KiKHaNK-Ms1OSaPpZIN3T_jxL-tr7XUOk87Pm6__6viYGqrL2oSfVy1PN6iJ4q7zAbzRLvoAdgEZl0NqJR4ETCFjGXzvoqOhDmOxvIwAGgo0B-lawcsFmQ46ODrQdBA7p9lHzi0znFbc613I3VXJKE.Dji2sVN77WqWtNzk4XbMPw',\n",
       " 'start': '2024-10-01',\n",
       " 'end': '2024-12-31',\n",
       " 'report': 'ProfitAndLossDetail',\n",
       " 'out_path': PosixPath('/home/zhe_rao/projects/ETLPipeline/Database/Bronze/QBO/PL/MFL/2024_10.json')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_MFL[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3295976a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MFL 3 partitions, others 5 partitions\n",
    "# MFL_partition = [extract_MFL[i::3] for i in range(3)]\n",
    "# other_partition = [extract_others[i::5] for i in range(5)]\n",
    "# partitions = MFL_partition + other_partition \n",
    "\n",
    "partitions = extract_MFL + extract_others\n",
    "len(partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aabe42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b29b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40836e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "114793ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_data_source(extract: list[dict[str,str]]) -> None:\n",
    "    \"\"\" \n",
    "        This function switch the \"report\" and \"out_path\" for each extract task to GL\n",
    "    \"\"\"\n",
    "    for task in extract:\n",
    "        task[\"report\"] = \"GeneralLedger\"\n",
    "        task[\"out_path\"] = BASE_DIR / config[\"directories\"][\"bronze\"][\"QBO\"][\"GL\"]/task[\"company\"]/(str(task[\"start\"][:4])+\"_\"+str(task[\"start\"][5:7])+\".json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76bfda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch_data_source(extract_MFL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6789d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company': 'MFL',\n",
       " 'realm_id': 123146146745069,\n",
       " 'token': 'eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwieC5vcmciOiJIMCJ9.._8X0pJLHP_d659Wi-fM_6g.pYNgSjJ6WJyM9_VwsinMA_4DbhEHEId9X7lp4GtXiveZwtwVg184l9b3krsxDqCDDc-Wzzc4R4lGF3kL4mSCgxQvwiGHhfpmTW70KAnWC_p-jVF-iKO8Mnw-PopgF5_HmIXe83qPZntZGNMdMahCVXk8AoFmfezJwJpJIZEQEa6sh5zCVaANcwwCcP2zq_ezByplJIrjpX1UJIj7fl78GW0KBuLeQrxCpbzJlvidR37CbzjpwM48rmKpgIE_p8zub7NLMFVuqWIRsFosfDvDh4devOt9aFAQ_gquIcXMBuL_IEmB-b8aZXGy_-GacAAvJ-rVHTvUna6Pq7qAXarP5KiKHaNK-Ms1OSaPpZIN3T_jxL-tr7XUOk87Pm6__6viYGqrL2oSfVy1PN6iJ4q7zAbzRLvoAdgEZl0NqJR4ETCFjGXzvoqOhDmOxvIwAGgo0B-lawcsFmQ46ODrQdBA7p9lHzi0znFbc613I3VXJKE.Dji2sVN77WqWtNzk4XbMPw',\n",
       " 'start': '2024-10-01',\n",
       " 'end': '2024-12-31',\n",
       " 'report': 'ProfitAndLossDetail',\n",
       " 'out_path': PosixPath('/home/zhe_rao/projects/ETLPipeline/Database/Bronze/QBO/PL/MFL/2024_10.json')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_MFL[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86343bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02900352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89dab11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c183c284",
   "metadata": {},
   "source": [
    "# Start Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb6aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "99371bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/11/12 16:27:05 WARN Utils: Your hostname, MFARM-AI resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/11/12 16:27:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/12 16:27:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# get Poetry's python path\n",
    "PY = subprocess.check_output(shlex.split(\"poetry env info --path\"), text=True).strip() + \"/bin/python\"\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "      .appName(\"test\")\n",
    "      .master(\"local[*]\")                           # use all cores during dev\n",
    "      .config(\"spark.local.ip\", \"127.0.0.1\")        # silences loopback complaints\n",
    "      .config(\"spark.driver.bindAddress\", \"127.0.0.1\")\n",
    "      .config(\"spark.driver.host\", \"127.0.0.1\")\n",
    "      .config(\"spark.pyspark.driver.python\", PY)    # ensure Poetry python on driver\n",
    "      .config(\"spark.pyspark.python\", PY)           # ...and executors\n",
    "      # .config(\"spark.python.use.daemon\", \"true\")  # default; faster\n",
    "      .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b21591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4636a8b",
   "metadata": {},
   "source": [
    "# PL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83aa0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41c7a15a",
   "metadata": {},
   "source": [
    "## extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24252a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d00093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_partition(it) -> None:\n",
    "    \"\"\" \n",
    "        This function processes tasks inside one partition\n",
    "            one task is extract raw content from QBO API call\n",
    "    \"\"\"\n",
    "    BASE_URL = \"https://quickbooks.api.intuit.com\"\n",
    "    minor_version = 75\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"Accept\": \"application/json\"})\n",
    "\n",
    "    # request_with_retry\n",
    "\n",
    "    for task in it:\n",
    "        session.headers.update({\n",
    "            \"Authorization\": f'Bearer {task[\"token\"]}',\n",
    "        })\n",
    "        realm_id = task[\"realm_id\"]\n",
    "        start = task[\"start\"]\n",
    "        end = task[\"end\"]\n",
    "        report_name = task[\"report\"]\n",
    "\n",
    "        url = f\"{BASE_URL}/v3/company/{realm_id}/reports/{report_name}\"\n",
    "        params = {\n",
    "            \"minorversion\": minor_version,\n",
    "            \"start_date\": start,\n",
    "            \"end_date\": end,\n",
    "            \"columns\": \"all\"\n",
    "        }\n",
    "\n",
    "        resp = session.get(url, params=params)\n",
    "        payload = resp.content\n",
    "\n",
    "        task[\"out_path\"].parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with open(task[\"out_path\"], \"wb\") as f:\n",
    "            f.write(payload)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36a12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cores = 8   # cannot expand this to more cores - QBO throttle\n",
    "rdd = spark.sparkContext.parallelize(partitions, cores * 3)\n",
    "rdd.foreachPartition(extract_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91e6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e75d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e45b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37e12fcf",
   "metadata": {},
   "source": [
    "## transform - stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea4dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1272371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24060c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44406fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/zhe_rao/projects/ETLPipeline/Database/Bronze/QBO/PL/MFL/2024_10.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = extract_MFL[0][\"out_path\"]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "636fe354",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, \"rb\") as f:\n",
    "    raw_bytes = f.read()\n",
    "data = orjson.loads(raw_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85b28e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Header', 'Rows', 'Summary', 'type'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Rows\"][\"Row\"][0][\"Rows\"][\"Row\"][1][\"Rows\"][\"Row\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d665b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TransactionDate': None,\n",
       " 'TransactionType': None,\n",
       " 'TransactionID': None,\n",
       " 'DocNumber': None,\n",
       " 'Name': None,\n",
       " 'NameID': None,\n",
       " 'Memo': None,\n",
       " 'SplitAcc': None,\n",
       " 'SplitAccID': None,\n",
       " 'Amount': None,\n",
       " 'Balance': None,\n",
       " 'Location': None,\n",
       " 'FarmID': None,\n",
       " 'Class': None,\n",
       " 'ClassID': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.fromkeys(list(project_config[\"PL\"][\"columns\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class col_MetaData(TypedDict):\n",
    "    Name: str\n",
    "    Value: str \n",
    "\n",
    "class col_types(TypedDict):\n",
    "    ColTitle: str \n",
    "    ColType: Literal[\"Date\", \"String\", \"Money\"]\n",
    "    MetaData: list[col_MetaData]\n",
    "\n",
    "def report_col(col_meta:list[col_types], col_map:dict[str,str]) -> list[str]:\n",
    "    \"\"\" \n",
    "        This function extract and standardize all columns from a given report, prevent positioanl drift (e.g., record class value under location column)\n",
    "        This function will account for the variations of different report - make the pipeline robust\n",
    "        when a standardized mapping cannot be found in col_map, the raw column name will be preserved and move forward to avoid pipeline disruption - logged later\n",
    "\n",
    "        args:    \n",
    "            col_meta is the json_file[\"Columns\"][\"Column\"] - list of meta data on report columns at the beginning of each QBO report\n",
    "            col_map is the mapping dictionary from configuration file - \"raw_name\" : \"standardized_name\" pair\n",
    "\n",
    "    \"\"\"\n",
    "    standardized_columns = []\n",
    "    for i in range(len(col_meta)):\n",
    "        raw_name = col_meta[i][\"MetaData\"][0][\"Value\"]\n",
    "        standardized_name = col_map.get(raw_name, raw_name)\n",
    "        standardized_columns.append(standardized_name)\n",
    "    return standardized_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bf482341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawler(json_level:dict, cols:list[str], company:str, acc_info:tuple[str]=None):\n",
    "    \"\"\" \n",
    "        this recursive function crawls into each node, yield/return leaf nodes extracted values\n",
    "\n",
    "        args:\n",
    "            json_level  - current node level in the json object - next level = json_level[\"Rows\"][\"Row\"]\n",
    "            cols        - the top level column names extraction at the report-level\n",
    "            company     - the company code for current report\n",
    "            acc_info    - (acc_ID, acc_fullname) information from last layer\n",
    "    \"\"\"\n",
    "    # determine if current node is a leaf node \n",
    "    if json_level[\"type\"] == \"Data\":\n",
    "        # keys = list(project_config[\"PL\"][\"columns\"].keys())\n",
    "        rows = dict.fromkeys(cols)\n",
    "        for i in range(len(cols)):\n",
    "            col_name = cols[i]\n",
    "            value = json_level[\"ColData\"][i]\n",
    "            if value[\"value\"] != '':    # record value only if it is not empty string\n",
    "                if col_name != \"DocNumber\":     # DocNumber column value requires adding company code at the beginning\n",
    "                    rows[col_name] = value[\"value\"]\n",
    "                else:\n",
    "                    rows[col_name] = company + \"-\" + value[\"value\"]\n",
    "                    continue        # no need to check and add company code again\n",
    "            value_id = value.get(\"id\", '')\n",
    "            if len(value_id) >= 1:\n",
    "                if col_name == \"TransactionType\":\n",
    "                    rows[\"TransactionID\"] = company + value_id\n",
    "                else:\n",
    "                    rows[col_name+\"ID\"] = company + value_id \n",
    "        if acc_info:    # record account information when it exist - should always exist - log if not\n",
    "            rows[\"AccID\"] = company + acc_info[0]\n",
    "            # accnum, accname = acc_info[1].split(\" \")\n",
    "            acc = acc_info[1]\n",
    "            rows[\"AccNum\"] = company + acc[:6]\n",
    "            rows[\"AccName\"] = company + acc[7:]\n",
    "        yield rows\n",
    "        \n",
    "    \n",
    "    # determine whether the account information should be recorded \n",
    "    header = json_level.get(\"Header\")\n",
    "    if isinstance(header, dict):\n",
    "        coldata = header.get(\"ColData\", {})\n",
    "        if coldata:\n",
    "            coldata = coldata[0]\n",
    "            if \"id\" in coldata and \"value\" in coldata:\n",
    "                acc_info = (coldata[\"id\"], coldata[\"value\"])\n",
    "    \n",
    "    # keep crawling forward if the next level exists\n",
    "    data = json_level.get(\"Rows\", {})\n",
    "    if \"Row\" in data:\n",
    "        for node_path in data[\"Row\"]:\n",
    "            yield from crawler(json_level=node_path,cols=cols,company=company,acc_info=acc_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5554ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_partition(it):\n",
    "    \"\"\" \n",
    "        this function iterate through one partition - go through individual jobs (correspond to one JSON file) - record global information and initiate crawler\n",
    "    \"\"\"\n",
    "    col_map = project_config[\"PL\"][\"columns_QBO_meta\"]\n",
    "    for task in it:\n",
    "        # extract company\n",
    "        company = task[\"company\"]\n",
    "        # load JSON\n",
    "        with open(task[\"out_path\"], \"rb\") as f:\n",
    "            raw_bytes = f.read()\n",
    "        data = orjson.loads(raw_bytes)\n",
    "        if data:\n",
    "            # extract columns \n",
    "            cols = report_col(data[\"Columns\"][\"Column\"],col_map)\n",
    "            # initiate crawler if there's data\n",
    "            if data.get(\"Rows\",{}):\n",
    "                for item in data[\"Rows\"][\"Row\"]:\n",
    "                    yield from crawler(json_level=item,cols=cols,company=company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c1c97f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ea491f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SCHEMA = T.StructType([\n",
    "    T.StructField(\"TransactionDate\", T.StringType(), nullable=False),\n",
    "    T.StructField(\"TransactionType\", T.StringType(), nullable=False),\n",
    "    T.StructField(\"TransactionID\", T.StringType(), nullable=False),\n",
    "    T.StructField(\"DocNumber\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"Name\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"NameID\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"Memo\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"SplitAcc\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"SplitAccID\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"Amount\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"Balance\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"Location\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"LocationID\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"Class\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"ClassID\", T.StringType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0b454f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = 8       # this can be infinitely expanded\n",
    "rdd = spark.sparkContext.parallelize(partitions, cores*4).mapPartitions(flatten_partition)\n",
    "df = spark.createDataFrame(rdd, schema=TARGET_SCHEMA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca808ab8",
   "metadata": {},
   "source": [
    "## create fiscal year and write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5766eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64294"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f7d4911",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65467960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ddfd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c1d872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad03d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770016d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-etl-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
